#!/usr/bin/env python3
"""
Launcher script for the LLM-powered chat client
"""

import subprocess
import sys
import os

def main():
    """Launch the LLM-powered Streamlit chat client"""
    
    # Get the project root directory
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(script_dir)
    client_path = os.path.join(project_root, "src", "clients", "chat_client_llm.py")
    
    # Check if the client exists
    if not os.path.exists(client_path):
        print("âŒ Error: chat_client_llm.py not found. Make sure the project structure is correct.")
        return
    
    print("ğŸ¤– Starting LLM-Powered Banking Transaction Chat Client...")
    print("ğŸ“± The chat interface will open in your web browser")
    print("ğŸ”— URL: http://localhost:8502")
    print("\nğŸ”§ Requirements:")
    print("   â€¢ LM Studio running on http://localhost:1234")
    print("   â€¢ A model loaded that supports tool calling")
    print("   â€¢ Elasticsearch with transaction data")
    print("\nğŸ’¡ This version uses your local LLM to:")
    print("   â€¢ Understand natural language queries")
    print("   â€¢ Automatically choose the right tools")
    print("   â€¢ Provide intelligent responses")
    print("\nâ¹ï¸  Press Ctrl+C to stop the server")
    
    # Launch Streamlit on a different port
    try:
        subprocess.run([
            sys.executable, "-m", "streamlit", "run", client_path,
            "--server.port", "8502",
            "--server.headless", "false",
            "--browser.gatherUsageStats", "false"
        ])
    except KeyboardInterrupt:
        print("\nğŸ‘‹ LLM chat client stopped.")

if __name__ == "__main__":
    main()
